#+OPTIONS: ':t *:t -:t ::t <:t H:5 \n:nil ^:{} arch:headline author:t
#+OPTIONS: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+OPTIONS: email:nil f:t inline:t num:nil p:t pri:nil prop:nil stat:t tags:t
#+OPTIONS: tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+TITLE: README
#+DATE: <2018-12-23 Sun>
#+AUTHOR: Nasy
#+EMAIL: nasyxx@gmail.com
#+LANGUAGE: en
#+SELECT_TAGS: export
#+EXCLUDE_TAGS: noexport
#+CREATOR: Emacs 27.0.50 (Org mode 9.1.9)

#+SETUPFILE: https://fniessen.github.io/org-html-themes/setup/theme-readtheorg.setup

* Prologue

Never had such a pure crawler like this ~nacf~.

Although I often write crawlers, I don't like to use huge frameworks, such as scrapy, but prefer
simple ~requests+bs4~ or more general ~requests_html~.  However, these two are inconvenient for a
crawler.  E.g. Places, such as error retrying or parallel crawling, need to be handwritten by
myself.  It is not very difficult to write it while writing too much can be tedious.  Hence I
started writing this nacf (Nasy Crawler Framework), hoping to simplify some error retrying or
parallel writing of crawlers.

* Packages

#+caption: Packages
| Package       | Version | Description                                        |
|---------------+---------+----------------------------------------------------|
| requests-html |   0.9.0 | HTML Parsing for Humans.                           |
| nalude        |   0.2.0 | A standard module.  Inspired by Haskell's Prelude. |

* Development Process

#+include: "./todo.org"

* Epoligue

** History

#+include: "./CHANGELOG"
